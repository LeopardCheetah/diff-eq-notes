\documentclass[../../diff_eqs.tex]{subfiles}

\begin{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% docs/syntax:

% definitions
% \begin{definition}[Definition]
%     Definition 1
% \end{definition}

% hr
% \hr

% exercise
% \begin{exercise}{problem number}
%
%    problem starts
% \end{exercise}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



Finally, we return to the opening section and consider differential equation systems of the form 
$$\matr{x'} = \matr{P}(t)x + \matr{g}(t)\text{.}$$

Like in section 3.5, we can express all solutions $\matr{x}$ as $\matr{x}_c + \matr{x}_p$ where $\matr{x}_c$ is the solution to the homogenous differential equation $\matr{x'} = \matr{P}\matr{x}$ and $\matr{x}_p$ is a solution to the nonhomogenous system described above. So how do we find $\matr{x}_p$?

\subsubsection{Diagonalization}

In the differential system $\matr{x'} = \matr{A}\matr{x} + \matr{g}$, if we assume $\matr{A}$ is diagonalizable, we can make the substitution $\matr{x} = \matr{T}\matr{y}$ and find 

$$\matr{T}\matr{y'} = \matr{A}\matr{T}\matr{y} + \matr{g} \ \rightarrow \ \matr{y'} = \matr{D}\matr{y} + \matr{T}^{-1}\matr{g}$$ 

which is simply a set of $n$ uncoupled (unrelated(?)) first order linear differential equations that can each be solved separately, and $\matr{x}$ can be recovered by left-multiplying $\matr{y}$ by $\matr{T}$. 

It is also possible to solve for $\matr{x}$ even if $\matr{A}$ is not diagonalizable by reducing $\matr{A}$ to a jordan form $\matr{J}$ (I have no clue what this is) from which it's possible to solve for $\matr{J}$ from the last row to the top (as most rows have differential equations that are not totally uncoupled).

\vspace{0.25cm}

If that seems too hard, you can always try the method of: 

\subsubsection{Undetermined Coefficients (Hard ver).}

(Note that this method is really only applicable when $\matr{P}$ is a bunch of constants and all terms in $\matr{g}$ look simple enough to be `guessed'.)

Note that the difficulty level in this mode of undetermined coefficients is upped since generally, if there is a term in $\matr{g}$ of the form $\matr{u}e^{\lambda t}$, the solution must be assumed to be of the form $\matr{a}te^{\lambda t} + \matr{b}e^{\lambda t}$ for coefficient constant matrices $\matr{a}$ and $\matr{b}$.

\subsubsection{Variation of Parameters}

Assuming a (general) fundamental matrix $\matr{\Psi}$ has been found for the homogenous version of the differential equation $\matr{x'} = \matr{P}\matr{x} + \matr{g}$, we seek solutions to the nonhomogenous system by replacing the constant vector $\matr{c}$ that would normally be multiplied to $\matr{\Psi}$ ($\matr{\Psi}\matr{c}$) by a vector of functions $\matr{u}$. Thus, letting $\matr{x} = \matr{\Psi}\matr{u}$, we have 

$$\matr{x'} = \matr{\Psi'}\matr{u} + \matr{\Psi}\matr{u'} = \matr{P}\matr{\Psi}\matr{u} + \matr{g} \ \rightarrow \ \matr{\Psi}\matr{u'} = \matr{g}$$ 

since $\matr{\Psi'} = \matr{P}\matr{\Psi}$ since $\matr{\Psi}$ is after all, a solution for the homogenous version of $\matr{x}$. 

\vspace{0.15cm}

Since the inverse of $\matr{\Psi}$ exists (since by definition the columns of $\matr{\Psi}$ ($\matr{x}^{(1)}$, $\dots$, $\matr{x}^{(n)}$) are linearly independent), 

$$\matr{u} = \int \matr{\Psi}^{-1}\matr{g} \ dt + \matr{c}$$

for arbitrary constant vector $\matr{c}$. Hopefully the integrals in the above equation can be evaluated because if not, a direct solution to the differential equation might not be possible \twemoji{skull}.\footnote{Me after reading this section: \twemoji{skull and crossbones}.}


\subsubsection{Laplace Transform (Hard Version)}

We can define a laplace transform over a vector as simply the vectors whos respective elemetns are the laplace transform of the elements in the original vector. 

By an extension of the Laplace transform then, 

$$\L{\matr{x'}(t)} = s\L{\matr{x}} - \matr{x}(0)$$

which means we can transform the differential system $\matr{x'} = \matr{A}\matr{x} + \matr{g}$ to $s\L{\matr{x}} - \matr{x}(0) = \matr{A}\L{\matr{x}} + \L{\matr{g}}$. For simplicity, if we are not solving an initial value problem, we can set $\matr{x}(0) = \matr{0}$ and do some messy calculations to find $\L{\matr{x}}$ from which we can do an inverse transform to find $\matr{x}$ (warning: messy).



\begin{exercise}{1}
    
    Letting $\begin{pmatrix}
        2 & -1 \\ 3 & -2 
    \end{pmatrix} = \matr{A}$ for simplicity, we thus have to solve $\matr{x'} = \matr{A}\matr{x} + \begin{pmatrix}
        e^t \\ t
    \end{pmatrix}$. 
    First, we find the general solution; chopping off the last term and solving a simple system with eigenvalues $\lambda = 1, -1$, we find our complementary solution to be $\matr{x_c} = \begin{pmatrix}
        1 \\ 1 
    \end{pmatrix}e^t + \begin{pmatrix}
        1 \\ 3
    \end{pmatrix}e^{-t}$. As such, we now seek a particular solution. 

    Using the method of undetermined coefficients, since $e^t$ is an eigenvalue root, we must assume that a particular solution $\matr{x_p}$ looks of the form $\matr{x_p} = \matr{a}te^t + \matr{b}e^t + \matr{c}t + \matr{d}$. Differentiating and plugging in both sides, we conclude that 

    $$\matr{a}te^t + (\matr{a} + \matr{b})e^t + \matr{c} = \matr{A}\matr{a}te^t + \matr{A}\matr{b}e^t + \matr{A}\matr{c}t + \matr{A}\matr{d} + \begin{pmatrix}
        1 \\ 0
    \end{pmatrix}e^t + \begin{pmatrix}
        0 \\ 1
    \end{pmatrix}t\text{.}$$

    Matching the coefficients ($te^t$, $e^t$, $t$, $1$) on both sides of the equation, we thus have the system 
    $$\begin{cases}
        \matr{Aa} = \matr{a} \\
        \matr{Ab} = \matr{a} + \matr{b} - \begin{pmatrix}
            1 \\ 0
        \end{pmatrix}  \\ 
        \matr{Ac} = \begin{pmatrix}
            0 \\ -1
        \end{pmatrix} \\ 
        \matr{A}\matr{d} = \matr{c}
    \end{cases}$$

    to solve. To take the simpler ones, the third equation simply tells us $\matr{c} = \begin{pmatrix}
        1 \\ 2
    \end{pmatrix}$ and similarly $\matr{d} = \begin{pmatrix}
        0 \\ -1
    \end{pmatrix}$. The first equation tells us $\matr{a}$ is of the form $\begin{pmatrix}
        \alpha \\ \alpha
    \end{pmatrix}$, and plugging that in to the second equation and rearranging, we have $(\matr{A} - \matr{I})\matr{b} = \begin{pmatrix}
        \alpha - 1 \\ \alpha
    \end{pmatrix}$. Since a simplification of the left hand side reveals $\begin{pmatrix}
        1 & -1 \\ 3 & -3 
    \end{pmatrix}\matr{b} = \begin{pmatrix}
        \alpha - 1 \\ \alpha
    \end{pmatrix}$, it follows that $3(\alpha - 1) = \alpha$ or $\alpha = \frac{3}{2}$ and thus the general solution for $\matr{b}$ is $\begin{pmatrix}
        \frac{1}{2} + k \\ k
    \end{pmatrix}$. Taking $k = 0$ for simplicity, our final answer to the equation (which an \href{https://mathdf.com/dif/}{online solver} agrees with) is 

    $$\matr{x} = c_1\begin{pmatrix}
        1 \\ 1 
    \end{pmatrix}e^t + c_2\begin{pmatrix}
        1 \\ 3
    \end{pmatrix}e^{-t} + \begin{pmatrix}
        \frac{3}{2} \\ \frac{3}{2}
    \end{pmatrix}te^t + \begin{pmatrix}
        \frac{1}{2} \\ 0
    \end{pmatrix}e^t + \begin{pmatrix}
        1 \\ 2
    \end{pmatrix}t + \begin{pmatrix}
        0 \\ -1
    \end{pmatrix}\text{.}$$
\end{exercise}

Note: for all the exercises below (and above, frankly), there's almost no consensus (from me, \href{https://www.wolframalpha.com}{wolfram alpha}, the textbook, and an \href{https://mathdf.com/dif/}{online solver}) on what the right answer is. Tread carefully.

\begin{exercise}{2}
    
    Again, we're going to let $\matr{A} = \begin{pmatrix}
        2 & -5 \\ 1 & -2
    \end{pmatrix}$ for ease of writing. Solving for the complementary solution yields eigenvalues of $\lambda = \pm i$ and a particular solution of $\matr{x_c} = c_1\begin{pmatrix}
        2 \cos t - \sin t \\ \cos t 
    \end{pmatrix} + c_2 \begin{pmatrix}
        2 \sin t + \cos t \\ \sin t
    \end{pmatrix}$. 

    Now for the fun part; the particular solution, and in this case, we'll use the method of variation of parameters. Recalling that our general matrix in this case is simply $\matr{\Psi} = \begin{pmatrix}
        x_1^{(1)} & x_1^{(2)} \\ x_2^{(1)} & x_2^{(2)}
    \end{pmatrix} = \begin{pmatrix}
        2 \cos t - \sin t & 2 \sin t + \cos t \\ \cos t & \sin t
    \end{pmatrix}$ (which has a non-zero Wronskian everywhere since $\det \matr{\Psi} = -1$), we can jump straight ahead to the conclusion and try to evaluate $\matr{u}$ by finding 
    $$\matr{u} = \int \matr{\Psi}^{-1}\matr{g} \ dt + \matr{c}\text{.}$$

    Recalling that an inverse of a 2-by-2 matrix $\begin{pmatrix}
        a & b \\ c & d
    \end{pmatrix}$ is $\frac{1}{ad - bc}\begin{pmatrix}
        d & -b \\ -c & a
    \end{pmatrix}$, it turns out we can simplify our above expression and find 

    $$\matr{u} = \int \begin{pmatrix}
        - \sin t & 2 \sin t + \cos t \\ \cos t & -2 \cos t + \sin t
    \end{pmatrix}\begin{pmatrix}
        - \cos t \\ \sin t
    \end{pmatrix} \ dt + \matr{c} = \int \begin{pmatrix}
        \sin(2t) + 1 - \cos(2t) \\  -\cos(2t) - \sin(2t)
    \end{pmatrix} \ dt + \matr{c}$$

    Integrating each part, we find 
    $$\matr{u} = \begin{pmatrix}
        t - \frac{1}{2}\sin(2t) - \frac{1}{2}\cos(2t) \\ \frac{1}{2}\cos(2t) - \frac{1}{2}\sin(2t)
    \end{pmatrix} + \matr{c}$$

    and taking $\matr{c} = 0$ and using the equation $\matr{x_{(p)}} = \matr{\Psi}\matr{u}$ (and many simplifications and tricky substitutions (notably $\sin(\alpha - \beta) = \sin\alpha\cos\beta - \sin\beta\cos\alpha$) and the cosine addition formula), we find that 
    $$\matr{x_p} = \begin{pmatrix}
        2t\cos(t) - t\sin(t) - \frac{3}{2}\sin(t) - \frac{1}{2}\cos(t)   \\   t\cos(t) - \frac{1}{2}\sin(t) - \frac{1}{2}\cos(t) 
    \end{pmatrix}$$

    so our final general solution is 

    $$\matr{x} = c_1\begin{pmatrix}
        2 \cos t - \sin t \\ \cos t 
    \end{pmatrix} + c_2 \begin{pmatrix}
        2 \sin t + \cos t \\ \sin t
    \end{pmatrix} + 
    \begin{pmatrix}
        2t\cos(t) - t\sin(t) - \frac{3}{2}\sin(t) - \frac{1}{2}\cos(t)   \\   t\cos(t) - \frac{1}{2}\sin(t) - \frac{1}{2}\cos(t) 
    \end{pmatrix}
    \text{.}$$
\end{exercise}


\begin{exercise}{3}

    To solve for a solution $\matr{x}$, we will use the method of diagonalization. First, we let $\matr{A} = \begin{pmatrix}
        1 & 1 \\ 4 & -2
    \end{pmatrix}$ and note it is diagonalizable with eigenvalues $\lambda = 2, -3$. Thus, we make the substitution $\matr{x} = \matr{T}\matr{y} = \begin{pmatrix}
        \xi_1^{(1)} & \xi_1^{(2)} \\ \xi_2^{(1)} & \xi_2^{(2)}
    \end{pmatrix}\matr{y} = \begin{pmatrix}
        1 & 1 \\ 1 & -4
    \end{pmatrix}\matr{y}$. As such, using this substitution and some properties, we derive 

    $$\matr{y'} = \matr{D}\matr{y} + \matr{T}^{-1}\matr{g} = \begin{pmatrix}
        2 & 0 \\ 0 & -3
    \end{pmatrix}\matr{y} + \frac{1}{5}\begin{pmatrix}
        4 & 1 \\ 1 & -1
    \end{pmatrix}\begin{pmatrix}
        e^{-2t} \\ -2e^t
    \end{pmatrix}\text{.}$$

    As such, letting $\matr{y} = \begin{pmatrix}
        y_1 \\ y_2
    \end{pmatrix}$, we can split the two differential equations and solve: 
    $$\matr{y'} = \begin{pmatrix}
        2 & 0 \\ 0 & -3
    \end{pmatrix}\matr{y} + \frac{1}{5}\begin{pmatrix}
        4e^{-2t} - 2e^t \\ e^{-2t} + 2e^t
    \end{pmatrix} \ \rightarrow \ \begin{cases}
        y_1' = 2y_1 + \frac{1}{5}(4e^{-2t} - 2e^t) \\ 
        y_2' = -3y_2 + \frac{1}{5}(e^{-2t} + 2e^t)
    \end{cases}\text{.}$$

    Since each equation is a first-order thats solvable, we can solve and get $y_1 = -\frac{1}{5}e^{-2t} + \frac{2}{5}e^t + c_1e^{2t}$ and $y_2 = \frac{1}{10}e^t + \frac{1}{5}e^{-2t} + c_2e^{-3t}$. As such, we can solve for $\matr{x}$ given that we have $\matr{T}$ and $\matr{y}$:

    $$\matr{x} = \matr{T}\matr{y} = \begin{pmatrix}
        1 & 1 \\ 1 & -4
    \end{pmatrix}\begin{pmatrix}
        -\frac{1}{5}e^{-2t} + \frac{2}{5}e^t + c_1e^{2t} \\ 
        \frac{1}{10}e^t + \frac{1}{5}e^{-2t} + c_2e^{-3t}
    \end{pmatrix} = \begin{pmatrix}
        -\frac{1}{5}e^{-2t} + \frac{2}{5}e^t + c_1e^{2t} + \frac{1}{10}e^t + \frac{1}{5}e^{-2t} + c_2e^{-3t} \\ 
        -\frac{1}{5}e^{-2t} + \frac{2}{5}e^t + c_1e^{2t} - \frac{2}{5}e^t - \frac{4}{5}e^{-2t} - 4c_2e^{-3t}
    \end{pmatrix}$$
    $$=\begin{pmatrix}
        \frac{1}{2}e^t + c_1e^{2t} + c_2e^{-3t} \\ 
        -e^{-2t} + c_1e^{2t} - 4c_2e^{-3t}
    \end{pmatrix} = \begin{pmatrix}
        0 \\ -1
    \end{pmatrix}e^{-2t} + \frac{1}{2}\begin{pmatrix}
        1 \\ 0
    \end{pmatrix}e^t + c_1\begin{pmatrix}
        1 \\ 1
    \end{pmatrix}e^{2t} + c_2\begin{pmatrix}
        1 \\ -4
    \end{pmatrix}e^{-3t}\text{.}$$ 
\end{exercise}


\begin{exercise}{4}

    A general solution to the homogenous version of this equation is $\matr{x_c} = c_1\begin{pmatrix}
        1 \\ 2
    \end{pmatrix} + c_2\begin{pmatrix}
        t + \frac{1}{4} \\ 2t 
    \end{pmatrix}$. 

    To find a particular solution, I will use the method of variation of parameters since $\matr{A}$ is not diagonalizable, $\matr{g}$ looks like it's made up of non-elementary functions, and a Laplace transform fails here. \\ 
    First, finding our fundamental matrix $\matr{\Psi}$, recall that $\matr{\Psi} = \begin{pmatrix}
        x_1^{(1)} & x_1^{(2)} \\ x_2^{(1)} & x_2^{(2)}
    \end{pmatrix} = \begin{pmatrix}
        1 & t + \frac{1}{4} \\ 2 & 2t 
    \end{pmatrix}$. Since the Wronksian (which is $\det \matr{\Psi}$) is non-zero everywhere, we can jump straight in and find $\matr{u}$ by evaluating 

    $$\matr{u} = \int \matr{\Psi}^{-1}\matr{g} \ dt + \matr{c}\text{.}$$

    So, we simply evaluate the integral; 
    $$\rightarrow \int \frac{1}{-\frac{1}{2}}\begin{pmatrix}
        2t & -t - \frac{1}{4} \\ -2 & 1
    \end{pmatrix} \begin{pmatrix}
        \frac{1}{t^3} \\ -\frac{1}{t^2}
    \end{pmatrix} \ dt + \matr{c} = -2 \int \begin{pmatrix}
        \frac{9}{4t^2} + \frac{1}{t} \\ -\frac{2}{t^3} - \frac{1}{t^2}
    \end{pmatrix} \ dt + \matr{c} = -2\begin{pmatrix}
        -\frac{9}{4t} + \ln t \\ \frac{1}{t^2} + \frac{1}{t}
    \end{pmatrix} + \matr{c}\text{.}$$

    Thus, $\matr{u}$ is whatever the garabge we got above. Then, since $\matr{x} = \matr{\Psi}\matr{u}$, we can simply do some matrix multiplication to find $\matr{x}$ (note: for simplicity, we let $\matr{c} = \matr{0}$):

    $$\matr{x} = -2\begin{pmatrix}
        1 & t + \frac{1}{4} \\ 2 & 2t 
    \end{pmatrix}\begin{pmatrix}
        -\frac{9}{4t} + \ln t \\ \frac{1}{t^2} + \frac{1}{t}
    \end{pmatrix} = \begin{pmatrix}
        \frac{2}{t} - 2\ln t - 2 - \frac{1}{2t^2} \\ \frac{5}{t} - 4 \ln t + -4
    \end{pmatrix}\text{.}$$

    As such, our final solution for $\matr{x}$ is 
    $$\matr{x} = c_1\begin{pmatrix}
        1 \\ 2
    \end{pmatrix} + c_2\begin{pmatrix}
        t + \frac{1}{4} \\ 2t 
    \end{pmatrix} + \begin{pmatrix}
        2 \\ 5
    \end{pmatrix}\frac{1}{t} - \begin{pmatrix}
        2 \\ 4
    \end{pmatrix}\ln t - \begin{pmatrix}
        1 \\ 0 
    \end{pmatrix}\frac{1}{2t^2}\text{.}$$
\end{exercise}


\begin{exercise}{5}
    
    To use the Laplace transform on this system of differential equations, we first should find a complementary solution, which we can do easily to get $\matr{x_c} = c_1\begin{pmatrix}
        1 \\ -2
    \end{pmatrix}e^{-t} + c_2\begin{pmatrix}
        1 \\ 2
    \end{pmatrix}e^{3t}$. 

    From here, to use the Laplace transform to solve this system, simply laplace transform the equation to get 

    $$s\L{\matr{x}} - \matr{x}(0) = \matr{A}\L{\matr{x}} + \L{\matr{g}} \ \rightarrow \ (s\matr{I} - \matr{A})\L{\matr{x}} = \begin{pmatrix}
        \frac{2}{s - 1} \\ -\frac{1}{s - 1}
    \end{pmatrix}$$

    where the assumption we're making for our particular solution is that $\matr{x}(0) = \matr{0}$. From here, we can simply calculate $(s\matr{I} - \matr{A})$ and left-multiply its inverse to both sides of the equation then do an inverse laplace transform to solve for $\matr{x}$:

    $$\rightarrow \begin{pmatrix}
        s - 1 & -1 \\ -4 & s - 1
    \end{pmatrix}\L{\matr{x}} = \begin{pmatrix}
        \frac{2}{s - 1} \\ -\frac{1}{s - 1}
    \end{pmatrix} \ \rightarrow \ \L{\matr{x}} = \left(\frac{1}{(s - 1)^2 - 4}\begin{pmatrix}
        s - 1 & 1 \\ 4 & s - 1
    \end{pmatrix}\right)\begin{pmatrix}
        \frac{2}{s - 1} \\ -\frac{1}{s - 1}
    \end{pmatrix}$$

    $$\rightarrow \L{\matr{x}} = \begin{pmatrix}
        \frac{2}{(s + 1)(s - 3)} - \frac{1}{(s - 1)(s + 1)(s - 3)} \\ \frac{8}{(s - 1)(s + 1)(s - 3)} - \frac{1}{(s + 1)(s - 3)}
    \end{pmatrix}\text{.}$$

    Leveraging partial fractions (namely: $\frac{1}{(s + 1)(s - 3)} = \frac{1}{4(s - 3)} - \frac{1}{4(s + 1)}$ and $\frac{1}{(s - 1)(s + 1)(s - 3)} = \frac{1}{8(s + 1)} + \frac{1}{8(s - 3)} - \frac{1}{4(s - 1)}$) and the simplicity that the inverse Laplace transform of $\frac{1}{s - a}$ is $e^{at}$, we quickly find that a solution for $\matr{x}$ is 

    $$\matr{x_p} = \frac{1}{8}\begin{pmatrix}
        3e^{3t} - 5e^{-t} + 2e^t \\ 
        6e^{3t} + 10e^{-t} - 16e^t
    \end{pmatrix}$$

    so a general solution would be 

    $$\matr{x} = \frac{1}{4}\begin{pmatrix}
        1 \\ 
        -8
    \end{pmatrix}e^t + c_1\begin{pmatrix}
        1 \\ -2
    \end{pmatrix}e^{-t} + c_2\begin{pmatrix}
        1 \\ 2
    \end{pmatrix}e^{3t}$$

    since the first two terms in the particular solution we found (that has the specific property that $\matr{x_p}(0) = \matr{0}$) can be eliminated by modifying $c_1$ and $c_2$.
\end{exercise}

\begin{exercise}{6}
    
    A general solution is $\matr{x_c} = c_1\begin{pmatrix}
        1 \\ 1
    \end{pmatrix}e^t + c_2\begin{pmatrix}
        1 \\ 3
    \end{pmatrix}e^{-t}$. Using the method of undetermined coefficients, we assume $\matr{x}$ is of the form $\matr{\alpha}te^t + \matr{\beta}e^t$. As such, we get the equation
    $$\matr{\alpha} e^t + \matr{\beta} e^t + \matr{\alpha} t e^t = \matr{A}\matr{\alpha}te^t + \matr{\alpha}\matr{\beta}e^t + \begin{pmatrix}
        1 \\ -1
    \end{pmatrix}e^t$$

    which when comparing coefficients gets us 
    $$\begin{cases}
        \matr{A}\matr{\alpha} = \matr{\alpha} \rightarrow \matr{\alpha} = \begin{pmatrix}
            a \\ a
        \end{pmatrix} \\ 
        \matr{A}\matr{\beta} = \matr{\alpha} + \matr{\beta} + \begin{pmatrix}
            -1 \\ 1
        \end{pmatrix}
    \end{cases}\text{.}$$

    Simplifying that second equation further, we have $(\matr{A} - \matr{I})\matr{\beta} = \matr{\alpha} + \begin{pmatrix}
        -1 \\ 1
    \end{pmatrix} \rightarrow \begin{pmatrix}
        1 & -1 \\ 3 & -3 
    \end{pmatrix}\matr{\beta} = \begin{pmatrix}
        a - 1 \\ a + 1
    \end{pmatrix}$ leading us to find $a = 2$ and the simplest form for $\matr{\beta}$ is $\matr{\beta} = (1, 0)^T$. As such, our final solution is 
    
    $$\matr{x} = c_1\begin{pmatrix}
        1 \\ 1
    \end{pmatrix}e^t + c_2\begin{pmatrix}
        1 \\ 3
    \end{pmatrix}e^{-t} + \begin{pmatrix}
        2 \\ 2
    \end{pmatrix}te^t + \begin{pmatrix}
        1 \\ 0
    \end{pmatrix}e^t\text{.}$$
\end{exercise}

\begin{exercise}{7}
    
    A general solution to the homogenous version of this differential equation is $\matr{x_c} = c_1\begin{pmatrix}
        1 \\ \sqrt{2}
    \end{pmatrix}e^{-t} + c_2\begin{pmatrix}
        \sqrt{2} \\ -1
    \end{pmatrix}e^{-4t}$. Using the method of undetermined coefficients and assuming $\matr{x} = \matr{\alpha}te^{-t} + \matr{\beta}e^{-t}$, we can once again set up equations similar to the ones above and find 
    $$\begin{cases}
        \matr{A}\matr{\alpha} = -\matr{\alpha} \\ 
        \matr{A}\matr{\beta} = \matr{\alpha} - \matr{\beta} + \begin{pmatrix}
            -1 \\ 1
        \end{pmatrix}
    \end{cases}\text{.}
    $$

    We can solve the first one to find that $\matr{\alpha}$ must be of the form $\begin{pmatrix}
        a \\ a\sqrt{2}
    \end{pmatrix}$, and a simplification like above for the second equation yields $\begin{pmatrix}
        -2 & \sqrt{2} \\ \sqrt{2} & -1 
    \end{pmatrix}\matr{\beta} = \begin{pmatrix}
        a - 1 \\ a\sqrt{2} + 1
    \end{pmatrix}$ leading us to find $a = \frac{1 - \sqrt{2}}{3}$ and a simple form for $\matr{\beta}$, namely $\matr{\beta} = \left(\frac{1}{3}, -\frac{1}{3}\right)^T$. Combining, we thus find a solution for $\matr{x}$ is 

    $$\matr{x} = c_1\begin{pmatrix}
        1 \\ \sqrt{2}
    \end{pmatrix}e^{-t} + c_2\begin{pmatrix}
        \sqrt{2} \\ -1
    \end{pmatrix}e^{-4t} + \frac{1}{3}\begin{pmatrix}
        1 - \sqrt{2} \\ \sqrt{2} - 2
    \end{pmatrix}te^{-t} + \frac{1}{3}\begin{pmatrix}
        1 \\ -1
    \end{pmatrix}e^{-t}\text{.}\footnote{The book gives some silly/crazy answer but I'm pretty sure my answer is right; their answer is derived from a different $\beta$ value.}$$
\end{exercise}

(I skipped 8 since I don't want to spend more time in hell. Also the solution I have for 8 is super sketchy.)

\begin{exercise}{9}

    9a. Recall that $\Psi(t) = \begin{pmatrix}
        x_1^{(1)} & x_1^{(2)} \\ x_2^{(1)} & x_2^{(2)}
    \end{pmatrix}$. Since a general solution for the homogenous linear system is $\matr{x} = c_1e^{-t/2}\begin{pmatrix}
        \cos(t/2) \\ 4 \sin(t/2) 
    \end{pmatrix} + c_2e^{-t/2}\begin{pmatrix}
        \sin(t/2) \\ -4\cos(t/2)
    \end{pmatrix}$, we can simply substitute these values in and find 
    $$\Psi = e^{-t/2}\begin{pmatrix}
        \cos(t/2) & \sin(t/2) \\  4 \sin(t/2) & -4\cos(t/2)
    \end{pmatrix}\text{.}$$

    9b. Since we want an initial condition of $\matr{x}(0) = \matr{0}$ to be satisfied, this seems like the perfect opportunity to pull out the Laplace transform!

    Namely, 
    $$s\L{\matr{x}} - \matr{x}(0) = \matr{A}\L{\matr{x}} + \L{\matr{g}} \ \rightarrow \ (s\matr{I} - \matr{A})\L{\matr{x}} = \begin{pmatrix}
        \frac{1}{2s + 1} \\ 0
    \end{pmatrix} \rightarrow \L{\matr{x}} = \frac{1}{(s + \frac{1}{2})^2 + \frac{1}{4}}\begin{pmatrix}
        s + \frac{1}{2} & -\frac{1}{8} \\ 2 & s + \frac{1}{2}
    \end{pmatrix}\begin{pmatrix}
        \frac{1}{2s + 1} \\ 0
    \end{pmatrix}$$

    $$= \frac{1}{(s + \frac{1}{2})^2 + \frac{1}{4}}\begin{pmatrix}
        \frac{1}{2} \\ \frac{2}{2s + 1}
    \end{pmatrix} = \left(
        \frac{\frac{1}{2}}{(s + \frac{1}{2})^2 + \left(\frac{1}{2}\right)^2}, \ \frac{4}{s + \frac{1}{2}} - 4\frac{(s + \frac{1}{2})}{(s + \frac{1}{2})^2 + \left(\frac{1}{2}\right)^2}
    \right)^T$$
    $$\longrightarrow \matr{x} = \left(e^{-t/2}\sin(t/2), \ 4e^{-t/2} - 4e^{-t/2}\cos(t/2) \right)^T$$

    so our particular solution that solves the problem and satisfies the given initial condition is 

    $$\matr{x} = e^{-\frac{t}{2}}\begin{pmatrix}
        \sin\left(\frac{t}{2}\right) \\ 4 - 4\cos\left(\frac{t}{2}\right)
    \end{pmatrix}\text{.}$$
\end{exercise}

\end{document}
